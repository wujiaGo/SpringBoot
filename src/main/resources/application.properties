#mysql驱动
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
#远程数据库链接 serverTimezone不可少
spring.datasource.url=jdbc:mysql://localhost:3306/springboot?useUnicode=true&characterEncoding=utf-8&serverTimezone=UTC&useSSL=false
#MySQL数据库用户名、密码
spring.datasource.username=root
spring.datasource.password=123456

mybatis-plus.mapper-locations=classpath:mapper/*.xml
mybatis-plus.configuration.log-impl= org.apache.ibatis.logging.stdout.StdOutImpl
# 全局逻辑删除的实体字段名(since 3.3.0,配置后可以不加步骤2的注解)
mybatis-plus.global-config.db-config.logic-delete-field=deletede
# 逻辑已删除值(默认为 1)
mybatis-plus.global-config.db-config.logic-delete-value=1
# 逻辑未删除值(默认为 0)
mybatis-plus.global-config.db-config.logic-not-delete-value=0

# kafka服务器地址(可以多个)
spring.kafka.bootstrap-servers=localhost:9092
# key/value的序列化
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.IntegerSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 返回数据形式
spring.kafka.producer.acks=all
# 批量抓取
#spring.kafka.producer.batch-size= 65536
# 缓存容量
spring.kafka.producer.buffer-memory=524288
# 服务器地址
spring.kafka.consumer.bootstrap-servers=localhost:9092
# key/value的反序列化
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.IntegerDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 指定一个默认的组名
spring.kafka.consumer.group-id=kafka2
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
#jdbc任务调度
spring.quartz.job-store-type=jdbc
#前缀
#spring.freemarker.prefix=classpath:/templates
#加直接访问
spring.resources.static-locations= classpath:/static/, classpath:/templates/